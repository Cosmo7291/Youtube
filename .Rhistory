# Create visualizations
library(ggplot2)
ggplot(merged_data, aes(x = subscribers, y = video.views)) +
geom_point(color = "darkblue") +
labs(title = "Subscribers vs Total Views",
x = "Subscribers", y = "Total Views") +
theme_minimal()
# Additional analysis based on the specific context and questions of interest
# Save the merged dataset
write.csv(merged_data, "merged_data.csv", row.names = FALSE)
ggplot(merged_data, aes(x = category)) + geom_bar(fill = "skyblue", color = "black") + labs(title = "Number of Uploads per Category", x = "Category", y = "Number of Uploads") + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(leaflet)
# Filter out rows with missing latitude or longitude
geo_data <- merged_data[!is.na(merged_data$Latitude) & !is.na(merged_data$Longitude), ]
# Clean up the Youtuber names to ensure valid UTF-8 characters
geo_data$Youtuber <- iconv(geo_data$Youtuber, from = "UTF-8", to = "ASCII//TRANSLIT")
# Create Leaflet map
map <- leaflet(geo_data) %>%
addTiles() %>%
addMarkers(~Longitude, ~Latitude, popup = ~Youtuber)
# Display the map
map
library(plotly)
color_scheme <- "blue"  # Replace with your actual color scheme
# Assuming you have a data frame called "merged_data" with columns "category" and "uploads"
plot_ly(merged_data, x = ~category, y = ~uploads, type = "bar", marker = list(color = color_scheme), height = 400, width = 600) %>%
layout(title = "Number of Uploads per Category",
xaxis = list(title = "Category"),
yaxis = list(title = "Number of Uploads"))
# Assuming color_scheme is defined elsewhere as a list
color_scheme <- list(color = "blue")  # Example color scheme, replace with your actual color scheme
# Interactive box plot: Distribution of total views by category
plot_ly(merged_data, x = ~category, y = ~X100M, type = "box", marker = color_scheme, height = 400, width = 600) %>%
layout(title = "Distribution of Total Views by Category",
xaxis = list(title = "Category"),
yaxis = list(title = "Total Views"))
# Set the locale explicitly
Sys.setlocale(category = "LC_ALL", locale = "C")
# Load required packages
library(ggplot2)
library(plotly)
# Assuming your data frame is named 'merged_data'
# Filter top 10 YouTubers based on views
top_10_youtubers <- merged_data[order(merged_data$video.views, decreasing = TRUE), ][1:10, ]
# Create a bar plot using ggplot2
bar_plot <- ggplot(top_10_youtubers, aes(x = reorder(Youtuber, video.views), y = video.views)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Top 10 YouTubers by Views",
x = "YouTuber",
y = "Views") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the plot directly
print(bar_plot)
# Load required libraries
library(dplyr)
library(ggplot2)
library(tm)
# Read the data with specified encoding
combined_data <- read.csv("merged_data.csv", encoding = "UTF-8")
combined_data <- read.csv("merged_data.csv", encoding = "latin1")
# Check data read-in
str(combined_data)
# Display the first few rows of the data
head(combined_data)
# Quantitative Analysis (Regression Model)
# For demonstration purposes, let's build a GLM to predict subscribers based on video views and uploads
glm_model <- glm(subscribers ~ video.views + uploads, data = combined_data, family = poisson)
# Summary of the regression model
summary(glm_model)
# Qualitative Analysis (Text Mining / Thematic Analysis)
# Preprocess text data
corpus <- Corpus(VectorSource(combined_data$Title))
# Perform text preprocessing
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
# Convert corpus to a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Perform thematic analysis using hierarchical clustering
dist_matrix <- dist(dtm)
clusters <- hclust(dist_matrix)
# Plot hierarchical clustering dendrogram
plot(clusters, hang = -1, cex = 0.8, main = "Hierarchical Clustering of Titles")
# Clustered Heatmap Visualization
library(pheatmap)
# Calculate similarity matrix
similarity_matrix <- as.matrix(dtm) %*% t(as.matrix(dtm))
# Create heatmap
pheatmap(similarity_matrix, clustering_method = "complete", main = "Clustered Heatmap of Titles")
# Load required libraries
library(dplyr)
library(ggplot2)
library(tm)
# Read the data with specified encoding
combined_data <- read.csv("merged_data.csv", encoding = "UTF-8")
combined_data <- read.csv("merged_data.csv", encoding = "latin1")
# Check data read-in
str(combined_data)
# Display the first few rows of the data
head(combined_data)
# Quantitative Analysis (Regression Model)
# For demonstration purposes, let's build a GLM to predict subscribers based on video views and uploads
glm_model <- glm(subscribers ~ video.views + uploads, data = combined_data, family = poisson)
# Summary of the regression model
summary(glm_model)
# Qualitative Analysis (Text Mining / Thematic Analysis)
# Preprocess text data
corpus <- Corpus(VectorSource(combined_data$Title))
# Perform text preprocessing
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
# Convert corpus to a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Perform thematic analysis using hierarchical clustering
dist_matrix <- dist(dtm)
clusters <- hclust(dist_matrix)
# Plot hierarchical clustering dendrogram
plot(clusters, hang = -1, cex = 0.8, main = "Hierarchical Clustering of Titles")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(tm)
library(stringi)
# Load the dataset
merged_data <- read.csv("merged_data.csv")
# Drop unnecessary columns
merged_data <- merged_data %>%
select(-c(Total.Views, X100M, Avg, Video.Name, Channel_Name, Views, Likes, Uploading.Date, Duration))
# Quantitative Analysis (Regression Model)
# Build a regression model to predict video views
model <- lm(video.views ~ subscribers + uploads + Population + Unemployment.rate + Urban_population, data = merged_data)
# Summary of the regression model
summary(model)
# Visualize the regression model
plot(model)
# Qualitative Analysis (Text Mining / Thematic Analysis)
# Combine video titles into a single text corpus
corpus <- Corpus(VectorSource(merged_data$Title))
# Convert the text data to "UTF-8" encoding
corpus <- tm_map(corpus, content_transformer(function(x) iconv(x, to = "UTF-8")))
# Preprocess the text data
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Find the most frequent terms
term_freq <- colSums(as.matrix(dtm))
top_terms <- sort(term_freq, decreasing = TRUE)[1:10]
# Display the top terms
print(top_terms)
# Visualize the top terms
barplot(top_terms, main = "Top Terms", ylab = "Frequency", las = 2, col = "lightblue")
# Assuming merged_data is your data frame and it has columns 'Youtuber', 'Rank', 'Highest_monthly_earnings', 'Lowest_monthly_earnings'
# Sort the data by Rank and select the top 5
merged_data <- merged_data[order(merged_data$rank),]
merged_data <- head(merged_data, 5)
# Convert earnings to a more readable format (in millions)
merged_data$Highest_monthly_earnings <- merged_data$highest_monthly_earnings / 1e6
merged_data$Lowest_monthly_earnings <- merged_data$lowest_monthly_earnings / 1e6
# Plotting
plot_ly(merged_data, x = ~rank, y = ~highest_monthly_earnings, type = 'scatter', mode = 'lines+markers', name = 'Highest Earnings', marker = list(color = 'blue'), hoverinfo = 'text', text = ~paste('Channel: ', Youtuber, '<br>Highest Earnings: $', Highest_monthly_earnings, 'M')) %>%
add_trace(y = ~lowest_monthly_earnings, name = 'Lowest Earnings', marker = list(color = 'red'), hoverinfo = 'text', text = ~paste('Channel: ', Youtuber, '<br>Lowest Earnings: $', lowest_monthly_earnings, 'M')) %>%
layout(title = 'Top 5 Youtubers: Highest and Lowest Monthly Earnings (in Millions)',
xaxis = list(title = 'Rank'),
yaxis = list(title = 'Earnings (in Millions)', tickmode = "array", tickvals = merged_data$Rank, ticktext = merged_data$Youtuber)) %>%
highlight(on = "plotly_hover", off = "plotly_doubleclick")
# Interactive line plot: Trend of subscribers over time
# Define a function to convert abbreviated month names to month numbers
abbrev_month_names_to_numbers <- function(abbrev_month_names) {
abbrev_month_names <- tolower(substr(abbrev_month_names, 1, 3))
match(abbrev_month_names, tolower(substr(month.abb, 1, 3)))
}
# Check unique values in the month column
unique_values <- unique(merged_data$month)
print(paste("Unique values in the month column:", paste(unique_values, collapse = ", ")))
# Check the data type of the month column
print(paste("Data type of the month column:", class(merged_data$month)))
# Check for missing or NA values
print(paste("Number of missing or NA values in the month column:", sum(is.na(merged_data$month))))
# Convert month names in merged_data to month numbers
merged_data$month_number <- abbrev_month_names_to_numbers(merged_data$created_month)
# Now plot with the updated data
plot_ly(data = merged_data, x = ~as.Date(month_number), y = ~subscribers, type = "scatter", mode = "lines",
line = list(color = "rgb(255, 100, 100)")) %>%
layout(title = "Trend of Subscribers Over Time",
xaxis = list(title = "Date"),
yaxis = list(title = "Subscribers"))
# Load necessary packages
library(dplyr)
# Generate Mermaid code for the diagram
mermaid_code <- "
graph TD;
A[global_youtube.csv] -->|Youtuber| C(merge)
B[top_artists.csv] -->|Artist| C
D[top_videos.csv] -->|Description| C
C --> E(merged_data.csv)
"
# Write the Mermaid code to a file
writeLines(mermaid_code, "mermaid_diagram.mmd")
# You can use any tool that supports Mermaid to render the diagram as an image.
# For example, you can use the Mermaid Live Editor (https://mermaid-js.github.io/mermaid-live-editor/) to render the diagram.
# Once the diagram is rendered, include it in your document using markdown syntax
cat("![Mermaid Diagram](path_to_rendered_image)")
# Generate Mermaid code for the diagram
mermaid_code <- "
graph TD;
A[global_youtube.csv] -->|Youtuber| C(merge)
B[top_artists.csv] -->|Artist| C
D[top_videos.csv] -->|Description| C
C --> E(merged_data.csv)
"
# Write the Mermaid code to a file
writeLines(mermaid_code, "mermaid_diagram.mmd")
```mermaid-svg
```mermaid-svg
# Generate Mermaid code for the diagram
mermaid_code <- "
graph TD;
A[global_youtube.csv] -->|Youtuber| C(merge)
B[top_artists.csv] -->|Artist| C
D[top_videos.csv] -->|Description| C
C --> E(merged_data.csv)
"
# Write the Mermaid code to a file
writeLines(mermaid_code, "mermaid_diagram.mmd")
graph LR
````{mermaid}
# Create a Mermaid diagram
mermaid("
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
install.packages("DiagrammeR")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
# Create a Mermaid diagram
mermaid("
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
")
# Save the Mermaid diagram as an image
export_graph("mermaid_diagram.png")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
library(dplyr)
# Load datasets
global_youtube <- read.csv("global_youtube_statistics.csv")
top_artists <- read.csv("topyoutube.csv")
top_videos <- read.csv("Top 14 Ever Most Viewed YouTube Videos.csv")
# Check the structure of datasets
str(global_youtube)
str(top_artists)
str(top_videos)
# Merge datasets
# Assuming there are common variables to merge on, such as Youtuber/Artist/Channel Name
merged_data <- merge(global_youtube, top_artists, by.x = "Youtuber", by.y = "Artist", all = TRUE)
merged_data <- merge(merged_data, top_videos, by.x = "Youtuber", by.y = "Description", all = TRUE)
# Check the structure of merged dataset
str(merged_data)
# Perform exploratory data analysis
# For example, you can calculate summary statistics
summary(merged_data)
# Create a Mermaid diagram
mermaid("
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
")
# Save the Mermaid diagram as an image
export_graph("mermaid_diagram.png")
# Create a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
DiagrammeR::mermaid(mermaid_diagram)
# Load necessary packages
library(dplyr)
library(DiagrammeR)
# Create visualizations
library(ggplot2)
ggplot(merged_data, aes(x = subscribers, y = video.views)) +
geom_point(color = "darkblue") +
labs(title = "Subscribers vs Total Views",
x = "Subscribers", y = "Total Views") +
theme_minimal()
# Additional analysis based on the specific context and questions of interest
# Save the merged dataset
write.csv(merged_data, "merged_data.csv", row.names = FALSE)
install.packages("grDevices")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
library(grDevices)
# Create a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
mermaid_graph <- DiagrammeR::mermaid(mermaid_diagram)
# Export the Mermaid diagram as an SVG file
svg_file <- DiagrammeR::export_graph(mermaid_graph, output = "mermaid_diagram.svg")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
library(grDevices)
library(rsvg)
install.packages("rsvg")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
library(grDevices)
library(rsvg)
# Create a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
mermaid_graph <- DiagrammeR::mermaid(mermaid_diagram)
# Export the Mermaid diagram as an SVG file
svg_file <- DiagrammeR::export_graph(mermaid_graph, output = "mermaid_diagram.svg")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
library(grDevices)
library(rsvg)
# Create a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
mermaid_graph <- DiagrammeR::mermaid(mermaid_diagram)
# Export the Mermaid diagram as an SVG file
svg_file <- htmlwidgets::saveWidget(mermaid_graph, "mermaid_diagram.svg")
# Convert the SVG file to a PNG image
png_file <- rsvg::rsvg_png(svg_file, "mermaid_diagram.png")
# Load necessary packages
library(dplyr)
library(DiagrammeR)
library(grDevices)
library(rsvg)
# Create a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
mermaid_graph <- DiagrammeR::mermaid(mermaid_diagram)
# Export the Mermaid diagram as an SVG file
svg_file <- htmlwidgets::saveWidget(mermaid_graph, "mermaid_diagram.svg")
# Read the SVG file content into a raw vector
svg_content <- charToRaw(readLines(svg_file))
# Load necessary packages
library(dplyr)
library(DiagrammeR)
library(grDevices)
library(rsvg)
# Create a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
mermaid_graph <- DiagrammeR::mermaid(mermaid_diagram)
# Export the Mermaid diagram as an HTML file
htmlwidgets::saveWidget(mermaid_graph, "mermaid_diagram.html")
# Load necessary packages
library(dplyr)
# Load datasets
global_youtube <- read.csv("global_youtube_statistics.csv")
top_artists <- read.csv("topyoutube.csv")
top_videos <- read.csv("Top 14 Ever Most Viewed YouTube Videos.csv")
# Check the structure of datasets
str(global_youtube)
str(top_artists)
str(top_videos)
# Merge datasets
# Assuming there are common variables to merge on, such as Youtuber/Artist/Channel Name
merged_data <- merge(global_youtube, top_artists, by.x = "Youtuber", by.y = "Artist", all = TRUE)
merged_data <- merge(merged_data, top_videos, by.x = "Youtuber", by.y = "Description", all = TRUE)
# Creating a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
DiagrammeR::mermaid(mermaid_diagram)
# Load necessary packages
library(dplyr)
suppressPackageStartupMessages(library(dplyr))
# Load datasets
global_youtube <- read.csv("global_youtube_statistics.csv")
top_artists <- read.csv("topyoutube.csv")
top_videos <- read.csv("Top 14 Ever Most Viewed YouTube Videos.csv")
# Check the structure of datasets
str(global_youtube)
str(top_artists)
str(top_videos)
# Merge datasets
# Assuming there are common variables to merge on, such as Youtuber/Artist/Channel Name
merged_data <- merge(global_youtube, top_artists, by.x = "Youtuber", by.y = "Artist", all = TRUE)
merged_data <- merge(merged_data, top_videos, by.x = "Youtuber", by.y = "Description", all = TRUE)
# Creating a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
DiagrammeR::mermaid(mermaid_diagram)
str(merged_data)
# Load necessary packages
suppressPackageStartupMessages(library(dplyr))
library(dplyr)
# Load datasets
global_youtube <- read.csv("global_youtube_statistics.csv")
top_artists <- read.csv("topyoutube.csv")
top_videos <- read.csv("Top 14 Ever Most Viewed YouTube Videos.csv")
# Check the structure of datasets
str(global_youtube)
str(top_artists)
str(top_videos)
# Merge datasets
# Assuming there are common variables to merge on, such as Youtuber/Artist/Channel Name
merged_data <- merge(global_youtube, top_artists, by.x = "Youtuber", by.y = "Artist", all = TRUE)
merged_data <- merge(merged_data, top_videos, by.x = "Youtuber", by.y = "Description", all = TRUE)
# Creating a Mermaid diagram
mermaid_diagram <- "
graph LR
A[global_youtube] --> C[merged_data]
B[top_artists] --> C
D[top_videos] --> C
"
# Render the Mermaid diagram
DiagrammeR::mermaid(mermaid_diagram)
***Lets start With the Structure of our dataset:***
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(tm)
library(stringi)
# Load the dataset
merged_data <- read.csv("merged_data.csv")
# Drop unnecessary columns
merged_data <- merged_data %>%
select(-c(Total.Views, X100M, Avg, Video.Name, Channel_Name, Views, Likes, Uploading.Date, Duration))
# Quantitative Analysis (Regression Model)
# Build a regression model to predict video views
model <- lm(video.views ~ subscribers + uploads + Population + Unemployment.rate + Urban_population, data = merged_data)
# Summary of the regression model
summary(model)
# Visualize the regression model
plot(model)
# Qualitative Analysis (Text Mining / Thematic Analysis)
# Combine video titles into a single text corpus
corpus <- Corpus(VectorSource(merged_data$Title))
# Convert the text data to "UTF-8" encoding
corpus <- tm_map(corpus, content_transformer(function(x) iconv(x, to = "UTF-8")))
# Preprocess the text data
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Find the most frequent terms
term_freq <- colSums(as.matrix(dtm))
top_terms <- sort(term_freq, decreasing = TRUE)[1:10]
# Display the top terms
print(top_terms)
# Visualize the top terms
barplot(top_terms, main = "Top Terms", ylab = "Frequency", las = 2, col = "lightblue")
